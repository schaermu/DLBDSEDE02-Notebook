{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantische Themen-Analyse mit LSI/LSA und LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung: Abhängigkeiten installieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import *\n",
    "import sys\n",
    "import warnings\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "from pprint import pprint\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -r ../requirements.txt\n",
    "!{sys.executable} -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Aktuelle Daten herunterladen\n",
    "Die Daten werden 1x pro Tag von `https://ordnungsamt.berlin.de/frontend.webservice.opendata/api/meldungen` heruntergeladen und im Ordner `../data` abgelegt. Alle folgenden Ausführungen am selben Tag werden exakt diese Daten verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "dataset_path = f\"../data/{current_date}.json\"\n",
    "base_model_folder = f\"../models/{current_date}\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"  Data already downloaded!\")\n",
    "else:\n",
    "    url = \"https://ordnungsamt.berlin.de/frontend.webservice.opendata/api/meldungen\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        with open(dataset_path, \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "    else:\n",
    "        print(\"  Error: Could not retrieve data from URL\")\n",
    "\n",
    "dataset = pd.read_json(dataset_path, orient=\"records\", typ=\"series\")\n",
    "dataset = pd.DataFrame(\n",
    "    map(\n",
    "        lambda x: {\n",
    "            \"msg_id\": x[\"id\"],\n",
    "            \"betreff\": x[\"betreff\"],\n",
    "            \"sachverhalt\": x[\"sachverhalt\"],\n",
    "        },\n",
    "        dataset[\"index\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Datensatz aufteilen und Texte vorverarbeiten\n",
    "In diesem Schritt erstelle ich zuerst 2 verschiedene Datensätze (einen Trainings- und einen Test-Datensatz) mit einer 80/20-Verteilung. Das Test-Set wird am Ende des Notebooks zum Testen der Modelle verwendet.\n",
    "\n",
    "Die Texte beider Datensätze werden danach wie folgt vorverarbeitet:\n",
    "* Tokenisierung\n",
    "* Entfernung von Stopwörtern, Punktuation und Zahlen\n",
    "* Lemmatisierung\n",
    "* PoS-Tagging (Part-of-Speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "\n",
    "\n",
    "def run_text_pipeline(df: pd.DataFrame):\n",
    "    df_tuple = zip(\n",
    "        # respect both subject and sachverhalt when processing\n",
    "        # df[df.columns[1:]].apply(lambda x: \" \".join(x.dropna().astype(str)), axis=1),\n",
    "        # only use sachverhalt for processing\n",
    "        df.sachverhalt.astype(str),\n",
    "        # set msg_id as context for later reference\n",
    "        df.msg_id.apply(lambda x: {\"msg_id\": x}),\n",
    "    )\n",
    "    docs = list(nlp.pipe(df_tuple, as_tuples=True))\n",
    "\n",
    "    # extract spacy tokens for filtering\n",
    "    tidy_df = extract_spacy_tokens(docs)\n",
    "\n",
    "    return (\n",
    "        tidy_df.loc[\n",
    "            # remove short tokens\n",
    "            tidy_df.lemma.apply(lambda x: len(x) > 2)\n",
    "            # remove stopwords/punctuations/digits\n",
    "            & ~tidy_df.is_stop\n",
    "            & ~tidy_df.is_punct\n",
    "            & ~tidy_df.is_digit\n",
    "            # only keep nouns\n",
    "            & tidy_df.pos.apply(lambda x: x == \"NOUN\")\n",
    "        ]\n",
    "        .groupby([\"msg_id\"])\n",
    "        .agg(lambda x: x.values.tolist())\n",
    "        .lemma\n",
    "    )\n",
    "\n",
    "\n",
    "# split into training, test and cross-validation set\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.15, random_state=200)\n",
    "test_data, cv_data = train_test_split(test_data, test_size=0.5, random_state=200)\n",
    "\n",
    "# define spacy pipeline\n",
    "nlp = spacy.load(\n",
    "    \"de_core_news_md\",\n",
    "    disable=[\n",
    "        \"textcat\",\n",
    "        \"transformer\",\n",
    "        \"textcat_multilabel\",\n",
    "        \"entity_ruler\",\n",
    "        \"attribute_ruler\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# cleanup sets\n",
    "training_set = run_text_pipeline(train_data)\n",
    "test_set = run_text_pipeline(test_data)\n",
    "cv_set = run_text_pipeline(cv_data)\n",
    "\n",
    "print(training_set.shape, test_set.shape, cv_set.shape)\n",
    "training_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Textvektorisierung mit BoW und TF-IDF\n",
    "In diesem Abschnitt vergleiche ich die zwei Textvektorisierungs-Methoden Bag-of-Words (BoW) und Term-Frequency Inverse-Document-Frequency (TF-IDF). Während Verben wie \"sehen\" oder \"stehen\" in einer reinen Wort-Frequenz-Zählung in den Top 5 rangieren, werden sie wegen ihrer generischen Natur von TF-IDF teilweise deutlich zurückgestuft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 1: Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_word_freq, plot_word_freq\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create bag-of-words corpus\n",
    "bow_dict = corpora.Dictionary()\n",
    "bow_corpus = [bow_dict.doc2bow(doc, allow_update=True) for doc in training_set.values]\n",
    "\n",
    "word_freq_bow = get_word_freq(bow_corpus, bow_dict)\n",
    "plot_word_freq(word_freq_bow, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 2: TF-IDF (Term-Frequency Inverse-Document-Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "# create tf-idf model\n",
    "tfidf_dict = corpora.Dictionary(training_set.values)\n",
    "tfidf = TfidfModel(dictionary=tfidf_dict, smartirs='ntc')\n",
    "tfidf_corpus = [tfidf[tfidf_dict.doc2bow(doc)] for doc in training_set.values]\n",
    "\n",
    "# get overall tf-idf scores\n",
    "word_freq_tfidf = get_word_freq(tfidf_corpus, tfidf_dict)\n",
    "plot_word_freq(word_freq_tfidf, 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Modell-Training\n",
    "Nun werde ich 2 verschiedene Varianten für die Themen-Extraktion vergleichen: Latent Semanting Indexing/Analysis (LSA/LSI) und Latent Dirichlet Allocation (LDA). In einem ersten Schritt werde ich für verschiedene Anzahl Themen (`num_topcs`-Parameter für das `LsiModel` resp. `LdaMulticore`) den Koheränz-Score berechnen und auf einem Diagramm visualisieren. Dies soll mir erlauben, für das spätere Modell-Training die optimale Anzahl Themen zu wählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 1: LSA-Modell trainieren\n",
    "Zuerst werde ich versuchen, die optimale Anzahl Themenfelder anhand eines Diagramms zu eruieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "lsa_dict = gensim.corpora.Dictionary(training_set.values)\n",
    "lsa_corpus = [lsa_dict.doc2bow(doc) for doc in training_set.values]\n",
    "\n",
    "start, stop, step = 2, 25, 1\n",
    "\n",
    "_, coherence_values = compute_coherence_values(\n",
    "    dict=lsa_dict,\n",
    "    corpus=lsa_corpus,\n",
    "    training_set=training_set.values,\n",
    "    model_type=\"lsi\",\n",
    "    coherence=\"u_mass\",\n",
    "    start=start, stop=stop, step=step\n",
    ")\n",
    "plot_coherence_graph(coherence_values, start, stop, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Diagram zeigt auf, dass die optimale Anzahl Themen bei ca. 15 liegt, mit höheren Werten pendelt sich der Coherence-Score auf einem höheren Niveau ein (wobei bei der u_mass Metrik der tiefste Wert der beste ist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15\n",
    "\n",
    "lsi_model = LsiModel(lsa_corpus, num_topics=num_topics, id2word=lsa_dict)\n",
    "topics = get_specific_topics(lsi_model)\n",
    "\n",
    "for topic_id, terms in topics.items():\n",
    "    print(f\"Topic {topic_id}:\")\n",
    "    for term, weight in terms:\n",
    "        print(f\"  {term}: {weight:.4f}\")\n",
    "\n",
    "# Compute Perplexity & Coherence Score\n",
    "coherence_model_lsa = CoherenceModel(\n",
    "    model=lsi_model, corpus=lsa_corpus, dictionary=lsa_dict, coherence=\"u_mass\"\n",
    ")\n",
    "coherence_lsa = coherence_model_lsa.get_coherence()\n",
    "print(\"Coherence Score: \", coherence_lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variante 2: LDA-Modell trainieren\n",
    "Als zweite Variante trainiere ich mit den Daten ein LDA-Modell (Latent Dirichlet Allocation) zur Ermittlung der Top-Themen in den Daten. Auch hier soll in einem ersten Schritt die ideale Anzahl Themen anhand des Coherence-Scores ermittelt werden (dieses mal auf Basis des `LdaMulticore`-Modells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "lda_dict = gensim.corpora.Dictionary(training_set.values)\n",
    "lda_corpus = [lda_dict.doc2bow(doc) for doc in training_set.values]\n",
    "\n",
    "start, stop, step = 2, 25, 1\n",
    "_, coherence_values = compute_coherence_values(\n",
    "    dict=lda_dict,\n",
    "    corpus=lda_corpus,\n",
    "    model_type=\"lda\",\n",
    "    training_set=training_set,\n",
    "    coherence=\"u_mass\",\n",
    "    start=start, stop=stop, step=step\n",
    ")\n",
    "plot_coherence_graph(coherence_values, start, stop, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei LDA zeigt sich zum einen eine tiefere Varianz in der Koheränz und zum anderen eine Verschiebung hin zu mehr Themenfelder. Wir trainieren das LDA-Modell mit 15 Themenfeldern und visualisieren die Resultate mit dem Python-Paket `pyLDAvis`, zur Evaluation wird wieder der Coherence-Score herangezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel, LdaMulticore\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "num_topics = 15\n",
    "\n",
    "# train model\n",
    "lda_model = LdaMulticore(\n",
    "    lda_corpus, num_topics=num_topics, id2word=lda_dict, passes=100, workers=4\n",
    ")\n",
    "\n",
    "# Compute Perplexity & Coherence Score\n",
    "coherence_model_lda = CoherenceModel(\n",
    "    model=lda_model, corpus=lda_corpus, dictionary=lda_dict, coherence=\"u_mass\"\n",
    ")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(\"Perplexity: \", lda_model.log_perplexity(lda_corpus))\n",
    "print(\"Coherence Score: \", coherence_lda)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, lda_corpus, lda_dict, sort_topics=False)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 5: LDA-Modell evaluieren\n",
    "Anhand des Test-Sets und der zugewiesenen Kategorien im Feld `betreff` werden wir nun prüfen, wie genau die Einordnungen des Modells sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_test_dict = gensim.corpora.Dictionary(test_set.values)\n",
    "lda_test_corpus = [lda_test_dict.doc2bow(doc) for doc in test_set.values]\n",
    "\n",
    "predictions = lda_model.get_document_topics(lda_test_corpus)\n",
    "\n",
    "dfs = []\n",
    "for i, preds in enumerate(predictions):\n",
    "    doc = test_set.iloc[i]\n",
    "    msg_id = test_set.keys()[i]\n",
    "\n",
    "    # get original subject/text from source data\n",
    "    subject = test_data[test_data.msg_id == msg_id].betreff.values[0]\n",
    "    text = test_data[test_data.msg_id == msg_id].sachverhalt.values[0]\n",
    "\n",
    "    # sort topics by score, get top topic and its top 5 terms\n",
    "    preds.sort(key=lambda x: x[1], reverse=True)\n",
    "    topic_id, probability = preds[0]\n",
    "    top_terms = [topic[0] for topic in lda_model.show_topic(topic_id, 5)[:5]]\n",
    "\n",
    "    doc_df = pd.DataFrame(\n",
    "        [(msg_id, subject, text, topic_id, top_terms, probability)],\n",
    "        columns=[\"msg_id\", \"subject\", \"text\", \"topic_id\", \"top_terms\", \"probability\"],\n",
    "    )\n",
    "    dfs.append(doc_df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
